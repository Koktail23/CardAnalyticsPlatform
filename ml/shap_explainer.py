#!/usr/bin/env python3
"""
SHAP –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ ML –º–æ–¥–µ–ª–µ–π
–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π Fraud Detection
"""

import shap
import pandas as pd
import numpy as np
from clickhouse_driver import Client
import joblib
import matplotlib.pyplot as plt
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelExplainer:
    """SHAP –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""

    def __init__(self):
        self.client = Client(
            host='localhost',
            port=9000,
            user='analyst',
            password='admin123',
            database='card_analytics'
        )
        self.models = {}
        self.load_models()

    def load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            self.models['fraud_xgb'] = joblib.load('fraud_xgboost.pkl')
            self.models['fraud_scaler'] = joblib.load('fraud_scaler.pkl')
            logger.info("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")

    def prepare_sample_data(self, n_samples=1000):
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""

        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ {n_samples} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ card_features
        query = """
        SELECT 
            txn_count_30d,
            txn_amount_30d,
            avg_txn_amount_30d,
            p2p_ratio_30d,
            unique_mcc_30d,
            unique_merchants_30d,
            weekend_ratio,
            night_txn_ratio,
            days_since_last_txn,
            max_daily_txn_count
        FROM card_features
        LIMIT {}
        """.format(n_samples)

        df = pd.DataFrame(self.client.execute(query))

        if df.empty:
            # –ï—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ card_features, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –≤ card_features, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ")
            np.random.seed(42)
            df = pd.DataFrame({
                'amount_uzs': np.random.lognormal(13, 2, n_samples),
                'hour_num': np.random.randint(0, 24, n_samples),
                'p2p_flag': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
                'days_since_prev_txn': np.random.exponential(5, n_samples),
                'amount_change_ratio': np.random.normal(1, 0.5, n_samples),
                'amount_deviation': np.random.normal(1, 0.3, n_samples),
                'txn_hour_count': np.random.poisson(3, n_samples),
                'is_risky_mcc': np.random.choice([0, 1], n_samples, p=[0.9, 0.1]),
                'is_weekend': np.random.choice([0, 1], n_samples, p=[0.7, 0.3]),
                'is_night': np.random.choice([0, 1], n_samples, p=[0.8, 0.2]),
                'is_capital': np.random.choice([0, 1], n_samples, p=[0.6, 0.4]),
                'txn_count_30d': np.random.poisson(10, n_samples),
                'avg_txn_amount_30d': np.random.lognormal(12, 1.5, n_samples),
                'p2p_ratio_30d': np.random.beta(2, 5, n_samples),
                'unique_mcc_30d': np.random.poisson(5, n_samples),
                'unique_merchants_30d': np.random.poisson(8, n_samples),
                'weekend_ratio': np.random.beta(2, 5, n_samples),
                'night_txn_ratio': np.random.beta(1, 9, n_samples)
            })
        else:
            # –ù–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫
            feature_names = [
                'txn_count_30d', 'txn_amount_30d', 'avg_txn_amount_30d',
                'p2p_ratio_30d', 'unique_mcc_30d', 'unique_merchants_30d',
                'weekend_ratio', 'night_txn_ratio', 'days_since_last_txn',
                'max_daily_txn_count'
            ]
            df.columns = feature_names

            # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            df['amount_uzs'] = df['avg_txn_amount_30d']
            df['hour_num'] = np.random.randint(0, 24, len(df))
            df['p2p_flag'] = (df['p2p_ratio_30d'] > 0.5).astype(int)
            df['days_since_prev_txn'] = df['days_since_last_txn']
            df['amount_change_ratio'] = np.random.normal(1, 0.5, len(df))
            df['amount_deviation'] = np.random.normal(1, 0.3, len(df))
            df['txn_hour_count'] = np.random.poisson(3, len(df))
            df['is_risky_mcc'] = np.random.choice([0, 1], len(df), p=[0.9, 0.1])
            df['is_weekend'] = (df['weekend_ratio'] > 0.3).astype(int)
            df['is_night'] = (df['night_txn_ratio'] > 0.2).astype(int)
            df['is_capital'] = np.random.choice([0, 1], len(df), p=[0.6, 0.4])

        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
        feature_columns = [
            'amount_uzs', 'hour_num', 'p2p_flag',
            'days_since_prev_txn', 'amount_change_ratio', 'amount_deviation',
            'txn_hour_count', 'is_risky_mcc', 'is_weekend', 'is_night', 'is_capital',
            'txn_count_30d', 'avg_txn_amount_30d', 'p2p_ratio_30d',
            'unique_mcc_30d', 'unique_merchants_30d', 'weekend_ratio', 'night_txn_ratio'
        ]

        X = df[feature_columns].fillna(0)

        return X

    def explain_fraud_model(self, X):
        """SHAP –∞–Ω–∞–ª–∏–∑ –¥–ª—è –º–æ–¥–µ–ª–∏ Fraud Detection"""

        if 'fraud_xgb' not in self.models:
            logger.error("–ú–æ–¥–µ–ª—å Fraud Detection –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return None

        logger.info("–ó–∞–ø—É—Å–∫ SHAP –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è Fraud Detection...")

        model = self.models['fraud_xgb']

        # –°–æ–∑–¥–∞–µ–º SHAP Explainer
        explainer = shap.Explainer(model, X)
        shap_values = explainer(X)

        # 1. Summary Plot - –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        plt.figure(figsize=(10, 6))
        shap.summary_plot(shap_values, X, show=False)
        plt.title("SHAP: –í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è Fraud Detection")
        plt.tight_layout()
        plt.savefig('shap_fraud_summary.png')
        plt.close()
        logger.info("‚úÖ Summary plot —Å–æ—Ö—Ä–∞–Ω–µ–Ω: shap_fraud_summary.png")

        # 2. Feature Importance Bar Plot
        plt.figure(figsize=(10, 6))
        shap.summary_plot(shap_values, X, plot_type="bar", show=False)
        plt.title("SHAP: –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        plt.tight_layout()
        plt.savefig('shap_fraud_importance.png')
        plt.close()
        logger.info("‚úÖ Importance plot —Å–æ—Ö—Ä–∞–Ω–µ–Ω: shap_fraud_importance.png")

        # 3. Waterfall –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
        plt.figure(figsize=(10, 6))
        shap.waterfall_plot(shap_values[0], show=False)
        plt.title("SHAP: –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
        plt.tight_layout()
        plt.savefig('shap_fraud_waterfall.png')
        plt.close()
        logger.info("‚úÖ Waterfall plot —Å–æ—Ö—Ä–∞–Ω–µ–Ω: shap_fraud_waterfall.png")

        # 4. Dependence plots –¥–ª—è —Ç–æ–ø –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        top_features = ['p2p_flag', 'amount_uzs', 'is_capital']
        for feature in top_features:
            if feature in X.columns:
                plt.figure(figsize=(8, 5))
                shap.dependence_plot(feature, shap_values.values, X, show=False)
                plt.title(f"SHAP: –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç {feature}")
                plt.tight_layout()
                plt.savefig(f'shap_dependence_{feature}.png')
                plt.close()
                logger.info(f"‚úÖ Dependence plot –¥–ª—è {feature} —Å–æ—Ö—Ä–∞–Ω–µ–Ω")

        return shap_values

    def generate_explanation_report(self, shap_values, X):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏—è–º–∏"""

        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ SHAP...")

        # –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': np.abs(shap_values.values).mean(axis=0)
        }).sort_values('importance', ascending=False)

        # –¢–æ–ø —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
        risk_factors = []
        for i in range(min(5, len(X))):
            transaction_shap = shap_values[i]
            top_positive = []
            top_negative = []

            for j, (feature, value) in enumerate(zip(X.columns, transaction_shap.values)):
                if value > 0.1:
                    top_positive.append((feature, value, X.iloc[i][feature]))
                elif value < -0.1:
                    top_negative.append((feature, value, X.iloc[i][feature]))

            risk_factors.append({
                'transaction_id': i,
                'fraud_probability': 'High' if sum(transaction_shap.values) > 0 else 'Low',
                'top_risk_factors': sorted(top_positive, key=lambda x: x[1], reverse=True)[:3],
                'top_safe_factors': sorted(top_negative, key=lambda x: x[1])[:3]
            })

        # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
        print("\n" + "=" * 60)
        print("üìä SHAP EXPLANATION REPORT")
        print("=" * 60)

        print("\nüéØ –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
        for idx, row in feature_importance.head(10).iterrows():
            print(f"  {idx + 1}. {row['feature']}: {row['importance']:.4f}")

        print("\nüîç –ê–Ω–∞–ª–∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π:")
        for factor in risk_factors[:3]:
            print(f"\n  –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è #{factor['transaction_id']}:")
            print(f"    –†–∏—Å–∫: {factor['fraud_probability']}")

            if factor['top_risk_factors']:
                print("    –§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞:")
                for feat, impact, value in factor['top_risk_factors']:
                    print(f"      ‚Ä¢ {feat} = {value:.2f} (–≤–ª–∏—è–Ω–∏–µ: +{impact:.3f})")

            if factor['top_safe_factors']:
                print("    –§–∞–∫—Ç–æ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:")
                for feat, impact, value in factor['top_safe_factors']:
                    print(f"      ‚Ä¢ {feat} = {value:.2f} (–≤–ª–∏—è–Ω–∏–µ: {impact:.3f})")

        print("\nüí° –ö–ª—é—á–µ–≤—ã–µ –∏–Ω—Å–∞–π—Ç—ã:")
        print("  ‚Ä¢ P2P —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏–º–µ—é—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä–∏—Å–∫")
        print("  ‚Ä¢ –ö—Ä—É–ø–Ω—ã–µ —Å—É–º–º—ã –ø–æ–≤—ã—à–∞—é—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ñ—Ä–æ–¥–∞")
        print("  ‚Ä¢ –ù–æ—á–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –±–æ–ª–µ–µ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã")
        print("  ‚Ä¢ –ß–∞—Å—Ç–æ—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤–ª–∏—è–µ—Ç –Ω–∞ –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–∞")

        print("\nüìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print("  ‚Ä¢ –£—Å–∏–ª–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ P2P –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
        print("  ‚Ä¢ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ª–∏–º–∏—Ç—ã –Ω–∞ –∫—Ä—É–ø–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
        print("  ‚Ä¢ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
        print("  ‚Ä¢ –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã —á–∞—Å—Ç–æ—Ç—ã —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π")

        print("\n" + "=" * 60)

        return feature_importance, risk_factors

    def run_full_analysis(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ SHAP –∞–Ω–∞–ª–∏–∑–∞"""

        print("\nüöÄ –ó–∞–ø—É—Å–∫ SHAP Analysis Pipeline...")

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        X = self.prepare_sample_data(n_samples=500)

        # SHAP –∞–Ω–∞–ª–∏–∑
        shap_values = self.explain_fraud_model(X)

        if shap_values is not None:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            feature_importance, risk_factors = self.generate_explanation_report(shap_values, X)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            feature_importance.to_csv('shap_feature_importance.csv', index=False)

            print("\n‚úÖ SHAP –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            print("\nüìÅ –°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
            print("  ‚Ä¢ shap_fraud_summary.png - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–∞–∂–Ω–æ—Å—Ç–∏")
            print("  ‚Ä¢ shap_fraud_importance.png - –≥—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏")
            print("  ‚Ä¢ shap_fraud_waterfall.png - –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏")
            print("  ‚Ä¢ shap_dependence_*.png - –≥—Ä–∞—Ñ–∏–∫–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π")
            print("  ‚Ä¢ shap_feature_importance.csv - —Ç–∞–±–ª–∏—Ü–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏")


def main():
    explainer = ModelExplainer()
    explainer.run_full_analysis()


if __name__ == "__main__":
    main()