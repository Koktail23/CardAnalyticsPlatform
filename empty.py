# ===================================
# TAB 6: Segmentation
# ===================================
with tab4:
    st.header("üë• Customer Segmentation")
    try:
        seg = ch_df("""
            SELECT cs.rfm_segment, cs.rfm_score,
                   cf.txn_amount_30d, cf.txn_count_30d, cf.p2p_ratio_30d, cf.days_since_last_txn
            FROM customer_segments cs
            LEFT JOIN card_features cf ON cs.hpan = cf.hpan
        """, ["rfm_segment", "rfm_score", "txn_amount_30d", "txn_count_30d", "p2p_ratio_30d", "days_since_last_txn"])
        if seg.empty:
            st.info("–ù–µ—Ç customer_segments/card_features. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–∞–π–ø–ª–∞–π–Ω —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏.")
        else:
            summary = seg.groupby("rfm_segment").agg(
                clients=("rfm_score", "count"),
                avg_amount=("txn_amount_30d", "mean"),
                avg_txn=("txn_count_30d", "mean"),
                avg_recency=("days_since_last_txn", "mean"),
                avg_p2p=("p2p_ratio_30d", "mean")
            ).reset_index()
            summary["share"] = (summary["clients"] / summary["clients"].sum() * 100)
            c1, c2 = st.columns([2, 3])
            with c1:
                st.subheader("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ RFM")
                st.plotly_chart(px.pie(summary, values="clients", names="rfm_segment", hole=0.45),
                                use_container_width=True)
            with c2:
                st.subheader("–ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —Å–µ–≥–º–µ–Ω—Ç–∞–º")
                show = summary[
                    ["rfm_segment", "clients", "share", "avg_amount", "avg_txn", "avg_recency", "avg_p2p"]].round(
                    2).rename(columns={
                    "rfm_segment": "–°–µ–≥–º–µ–Ω—Ç", "clients": "–ö–ª–∏–µ–Ω—Ç–æ–≤", "share": "–î–æ–ª—è,%", "avg_amount": "Avg –æ–±—ä—ë–º",
                    "avg_txn": "Avg —á–∞—Å—Ç–æ—Ç–∞", "avg_recency": "Avg Recency (–¥–Ω.)", "avg_p2p": "Avg P2P"
                })
                st.dataframe(show, use_container_width=True)
                st.download_button("‚¨áÔ∏è CSV (–º–µ—Ç—Ä–∏–∫–∏)", data=show.to_csv(index=False).encode("utf-8"),
                                   file_name="segments_metrics.csv")

            st.subheader("R√óF heatmap (–∏–∑ RFM_score)")
            tmp = seg.copy()
            tmp["R"] = tmp["rfm_score"].str[0].astype(str)
            tmp["F"] = tmp["rfm_score"].str[1].astype(str)
            hmp = tmp.pivot_table(index="R", columns="F", values="rfm_score", aggfunc="count").fillna(0)
            st.plotly_chart(px.imshow(hmp, text_auto=True, color_continuous_scale="Blues"), use_container_width=True)

            st.subheader("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
            st.markdown("""
- üèÜ Champions ‚Äî —É–¥–µ—Ä–∂–∞–Ω–∏–µ, –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ VIP-–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è  
- üíé Loyal ‚Äî –∫—Ä–æ—Å—Å/–∞–ø—Å–µ–π–ª, –ø—Ä–æ–≥—Ä–∞–º–º—ã –ª–æ—è–ª—å–Ω–æ—Å—Ç–∏  
- üå± Potential ‚Äî welcome-–∫–∞–º–ø–∞–Ω–∏–∏  
- ‚ö†Ô∏è At Risk ‚Äî —Ä–µ–∞–∫—Ç–∏–≤–∞—Ü–∏—è  
- üò¥ Hibernating ‚Äî win-back  
- ‚ùå Lost ‚Äî –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π win-back –∏–ª–∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
""")
    except Exception as e:
        st.error(f"Segmentation: {e}")

# ===================================
# TAB 7: Enhanced Forecasting
# ===================================
with tab5:
    st.header("üìä Enhanced Forecasting")
    st.caption(f"–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–æ–π")

    # Forecast mode selector
    forecast_mode = st.radio(
        "–†–µ–∂–∏–º –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è",
        ["üìà –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑", "üî¨ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä—è–¥–æ–≤", "üìä –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π", "üéØ –°—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑"],
        horizontal=True
    )

    if forecast_mode == "üìà –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–≥–Ω–æ–∑":
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞")

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            metric_to_forecast = st.selectbox(
                "–ú–µ—Ç—Ä–∏–∫–∞",
                ["volume", "transactions", "unique_cards"],
                format_func=lambda x: {
                    "volume": "–û–±—ä—ë–º (UZS)",
                    "transactions": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π",
                    "unique_cards": "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞—Ä—Ç—ã"
                }[x]
            )
        with col2:
            forecast_horizon = st.number_input("–ì–æ—Ä–∏–∑–æ–Ω—Ç (–¥–Ω–µ–π)", 7, 90, 14)
        with col3:
            holdout_days = st.number_input("Holdout (–¥–Ω–µ–π)", 0, 30, 14)
        with col4:
            confidence_level = st.selectbox("–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª", [80, 90, 95], index=2)

        if st.button("üöÄ –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑", type="primary"):
            if HAS_ENHANCED_FORECAST:
                try:
                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                        # Get historical data
                        if metric_to_forecast == "volume":
                            query = f"""
                            SELECT 
                                toDate(transaction_date) AS date,
                                sum(amount_uzs) AS value
                            FROM {selected_table}
                            WHERE transaction_date >= today() - INTERVAL 120 DAY
                            GROUP BY date
                            ORDER BY date
                            """
                        elif metric_to_forecast == "transactions":
                            query = f"""
                            SELECT 
                                toDate(transaction_date) AS date,
                                count() AS value
                            FROM {selected_table}
                            WHERE transaction_date >= today() - INTERVAL 120 DAY
                            GROUP BY date
                            ORDER BY date
                            """
                        else:  # unique_cards
                            if has_col(selected_table, "hpan"):
                                query = f"""
                                SELECT 
                                    toDate(transaction_date) AS date,
                                    uniq(hpan) AS value
                                FROM {selected_table}
                                WHERE transaction_date >= today() - INTERVAL 120 DAY
                                GROUP BY date
                                ORDER BY date
                                """
                            else:
                                st.error("–ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ hpan –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ä—Ç")
                                query = None

                        if query:
                            df = ch_df(query)
                            df.columns = ["date", metric_to_forecast]
                        else:
                            df = pd.DataFrame()

                    if not df.empty:
                        # Initialize forecaster
                        forecaster = EnhancedForecaster()

                        # Prepare data
                        train, holdout = forecaster.prepare_data(
                            df,
                            value_col=metric_to_forecast,
                            holdout_days=holdout_days
                        )

                        with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–æ–≤..."):
                            # Generate multiple forecasts
                            forecasts = []
                            forecast_names = []

                            # Seasonal Naive
                            naive_fc = forecaster.seasonal_naive_forecast(
                                train, forecast_horizon, value_col=metric_to_forecast
                            )
                            forecasts.append(naive_fc)
                            forecast_names.append("Seasonal Naive")

                            # Prophet if available
                            prophet_fc = forecaster.prophet_forecast(
                                train, forecast_horizon, value_col=metric_to_forecast
                            )
                            if prophet_fc is not None:
                                forecasts.append(prophet_fc)
                                forecast_names.append("Prophet")

                            # Ensemble
                            ensemble = forecaster.ensemble_forecast(forecasts)

                        # Evaluate on holdout if available
                        metrics_dict = {}
                        if len(holdout) > 0:
                            st.info(f"üìä –û—Ü–µ–Ω–∫–∞ –Ω–∞ holdout –ø–µ—Ä–∏–æ–¥–µ ({holdout_days} –¥–Ω–µ–π)")

                            cols = st.columns(len(forecasts) + 1)

                            for i, (fc, name) in enumerate(zip(forecasts, forecast_names)):
                                metrics = forecaster.evaluate_forecast(
                                    fc, holdout, train, value_col=metric_to_forecast
                                )
                                metrics_dict[name] = metrics

                                with cols[i]:
                                    st.markdown(f"**{name}**")
                                    if "mape" in metrics:
                                        st.metric("MAPE", f"{metrics['mape']:.1f}%")
                                    if "coverage_95" in metrics:
                                        st.metric("Coverage 95%", f"{metrics['coverage_95']:.0f}%")

                            # Ensemble metrics
                            ensemble_metrics = forecaster.evaluate_forecast(
                                ensemble, holdout, train, value_col=metric_to_forecast
                            )
                            metrics_dict["Ensemble"] = ensemble_metrics

                            with cols[-1]:
                                st.markdown("**üéØ Ensemble**")
                                if "mape" in ensemble_metrics:
                                    st.metric("MAPE", f"{ensemble_metrics['mape']:.1f}%")
                                if "coverage_95" in ensemble_metrics:
                                    st.metric("Coverage 95%", f"{ensemble_metrics['coverage_95']:.0f}%")

                        # Visualization
                        st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≥–Ω–æ–∑–∞")

                        fig = go.Figure()

                        # Historical data
                        fig.add_trace(go.Scatter(
                            x=train["date"],
                            y=train[metric_to_forecast],
                            mode="lines",
                            name="–ò—Å—Ç–æ—Ä–∏—è",
                            line=dict(color="black", width=2)
                        ))

                        # Holdout if available
                        if len(holdout) > 0:
                            fig.add_trace(go.Scatter(
                                x=holdout["date"],
                                y=holdout[metric_to_forecast],
                                mode="markers",
                                name="Holdout (—Ñ–∞–∫—Ç)",
                                marker=dict(color="red", size=8)
                            ))

                        # Forecasts
                        colors = ["blue", "green", "purple", "orange"]
                        for fc, name, color in zip(forecasts, forecast_names, colors):
                            fig.add_trace(go.Scatter(
                                x=fc["date"],
                                y=fc["yhat"],
                                mode="lines",
                                name=f"{name} –ø—Ä–æ–≥–Ω–æ–∑",
                                line=dict(color=color, width=1, dash="dot")
                            ))

                        # Ensemble with confidence interval
                        fig.add_trace(go.Scatter(
                            x=ensemble["date"],
                            y=ensemble["yhat_upper"],
                            mode="lines",
                            name="Upper bound",
                            line=dict(width=0),
                            showlegend=False
                        ))

                        fig.add_trace(go.Scatter(
                            x=ensemble["date"],
                            y=ensemble["yhat_lower"],
                            mode="lines",
                            name="Lower bound",
                            line=dict(width=0),
                            fillcolor="rgba(68, 68, 68, 0.2)",
                            fill="tonexty",
                            showlegend=False
                        ))

                        fig.add_trace(go.Scatter(
                            x=ensemble["date"],
                            y=ensemble["yhat"],
                            mode="lines+markers",
                            name="Ensemble –ø—Ä–æ–≥–Ω–æ–∑",
                            line=dict(color="red", width=2),
                            marker=dict(size=6)
                        ))

                        fig.update_layout(
                            title=f"–ü—Ä–æ–≥–Ω–æ–∑: {metric_to_forecast}",
                            xaxis_title="–î–∞—Ç–∞",
                            yaxis_title={
                                "volume": "–û–±—ä—ë–º (UZS)",
                                "transactions": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ",
                                "unique_cards": "–ö–∞—Ä—Ç—ã"
                            }[metric_to_forecast],
                            height=500,
                            hovermode="x unified"
                        )

                        st.plotly_chart(fig, use_container_width=True)

                        # Export results
                        with st.expander("üíæ –≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"):
                            # Prepare export data
                            export_df = ensemble.copy()
                            export_df["metric"] = metric_to_forecast
                            export_df["model"] = "ensemble"

                            # Add metrics if available
                            if metrics_dict:
                                st.json(metrics_dict)

                            # Download buttons
                            col1, col2 = st.columns(2)
                            with col1:
                                csv = export_df.to_csv(index=False)
                                st.download_button(
                                    "üì• –°–∫–∞—á–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ (CSV)",
                                    data=csv,
                                    file_name=f"forecast_{metric_to_forecast}_{datetime.now():%Y%m%d}.csv",
                                    mime="text/csv"
                                )

                            with col2:
                                if metrics_dict:
                                    metrics_json = json.dumps(metrics_dict, indent=2)
                                    st.download_button(
                                        "üìä –°–∫–∞—á–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ (JSON)",
                                        data=metrics_json,
                                        file_name=f"metrics_{metric_to_forecast}_{datetime.now():%Y%m%d}.json",
                                        mime="application/json"
                                    )
                    else:
                        st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")

                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            else:
                st.error("Enhanced Forecasting –º–æ–¥—É–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –í—ã–ø–æ–ª–Ω–∏—Ç–µ: pip install statsmodels prophet")

    elif forecast_mode == "üî¨ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä—è–¥–æ–≤":
        st.subheader("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤")

        if HAS_ENHANCED_FORECAST:
            try:
                # Load time series
                query = f"""
                SELECT 
                    toDate(transaction_date) AS date,
                    sum(amount_uzs) AS volume,
                    count() AS transactions
                FROM {selected_table}
                WHERE transaction_date >= today() - INTERVAL 90 DAY
                GROUP BY date
                ORDER BY date
                """
                df = ch_df(query)

                if not df.empty:
                    df.columns = ["date", "volume", "transactions"]

                    # Select series to diagnose
                    series_name = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ä—è–¥", ["volume", "transactions"])

                    # Initialize diagnostics
                    diagnostics = TimeSeriesDiagnostics()

                    # STL decomposition
                    with st.spinner("–í—ã–ø–æ–ª–Ω—è—é STL –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—é..."):
                        ts = pd.Series(
                            df[series_name].values,
                            index=pd.DatetimeIndex(df["date"])
                        )

                        stl_result = diagnostics.stl_decompose(ts)

                    if stl_result:
                        # Display decomposition
                        st.subheader("üìä STL –î–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è")

                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric(
                                "–°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞",
                                f"{stl_result.get('strength_trend', 0):.2f}",
                                help="–ë–ª–∏–∑–∫–æ –∫ 1 = —Å–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥"
                            )
                        with col2:
                            st.metric(
                                "–°–∏–ª–∞ —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏",
                                f"{stl_result.get('strength_seasonal', 0):.2f}",
                                help="–ë–ª–∏–∑–∫–æ –∫ 1 = —Å–∏–ª—å–Ω–∞—è —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å"
                            )

                        # Plot components
                        fig = go.Figure()

                        components = ["trend", "seasonal", "residual"]
                        for i, comp in enumerate(components):
                            if comp in stl_result:
                                fig.add_trace(go.Scatter(
                                    x=df["date"],
                                    y=stl_result[comp],
                                    mode="lines",
                                    name=comp.capitalize()
                                ))

                        fig.update_layout(
                            title="–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ä—è–¥–∞",
                            xaxis_title="–î–∞—Ç–∞",
                            height=400
                        )

                        st.plotly_chart(fig, use_container_width=True)

                    # Anomaly detection
                    st.subheader("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π")

                    anomalies = diagnostics.detect_anomalies(ts, threshold=2.5)
                    anomaly_dates = df.loc[anomalies, "date"].tolist()

                    if anomaly_dates:
                        st.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(anomaly_dates)} –∞–Ω–æ–º–∞–ª–∏–π")

                        # Plot with anomalies
                        fig = go.Figure()

                        fig.add_trace(go.Scatter(
                            x=df["date"],
                            y=df[series_name],
                            mode="lines",
                            name="–î–∞–Ω–Ω—ã–µ"
                        ))

                        fig.add_trace(go.Scatter(
                            x=df.loc[anomalies, "date"],
                            y=df.loc[anomalies, series_name],
                            mode="markers",
                            name="–ê–Ω–æ–º–∞–ª–∏–∏",
                            marker=dict(color="red", size=10)
                        ))

                        fig.update_layout(
                            title=f"–ê–Ω–æ–º–∞–ª–∏–∏ –≤ {series_name}",
                            xaxis_title="–î–∞—Ç–∞",
                            height=350
                        )

                        st.plotly_chart(fig, use_container_width=True)

                        # List anomaly dates
                        with st.expander("–î–∞—Ç—ã –∞–Ω–æ–º–∞–ª–∏–π"):
                            for d in anomaly_dates:
                                st.write(f"‚Ä¢ {d}")
                    else:
                        st.success("–ê–Ω–æ–º–∞–ª–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")

                    # Autocorrelation test
                    st.subheader("üìà –¢–µ—Å—Ç –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏")

                    # Calculate residuals (simple detrending)
                    residuals = ts - ts.rolling(window=7, center=True).mean()
                    residuals = residuals.dropna()

                    ljung_result = diagnostics.ljung_box_test(residuals, lags=14)

                    if ljung_result:
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric(
                                "Ljung-Box —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞",
                                f"{ljung_result.get('statistic', 0):.2f}"
                            )
                        with col2:
                            st.metric(
                                "P-value",
                                f"{ljung_result.get('p_value', 1):.4f}",
                                help="< 0.05 –æ–∑–Ω–∞—á–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏"
                            )

                        if ljung_result.get("autocorrelated"):
                            st.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –≤ –æ—Å—Ç–∞—Ç–∫–∞—Ö")
                        else:
                            st.success("‚úÖ –ê–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞")

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")
        else:
            st.error("Enhanced Forecasting –º–æ–¥—É–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    elif forecast_mode == "üìä –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π":
        st.subheader("Rolling Origin Cross-Validation")

        if HAS_ENHANCED_FORECAST:
            col1, col2, col3 = st.columns(3)
            with col1:
                n_splits = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤", 2, 10, 3)
            with col2:
                test_size = st.number_input("–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–∞ (–¥–Ω–µ–π)", 7, 30, 14)
            with col3:
                metric_name = st.selectbox("–ú–µ—Ç—Ä–∏–∫–∞", ["volume", "transactions"])

            if st.button("üîÑ –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é", type="primary"):
                try:
                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
                        query = f"""
                        SELECT 
                            toDate(transaction_date) AS date,
                            {"sum(amount_uzs)" if metric_name == "volume" else "count()"} AS value
                        FROM {selected_table}
                        WHERE transaction_date >= today() - INTERVAL 180 DAY
                        GROUP BY date
                        ORDER BY date
                        """
                        df = ch_df(query)
                        df.columns = ["date", metric_name]

                    if not df.empty:
                        # Initialize forecaster
                        forecaster = EnhancedForecaster()

                        with st.spinner(f"–í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ {n_splits} —Ñ–æ–ª–¥–∞—Ö..."):
                            cv_results = forecaster.rolling_origin_validation(
                                df,
                                n_splits=n_splits,
                                test_size=test_size,
                                value_col=metric_name
                            )

                        if not cv_results.empty:
                            # Summary statistics
                            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–∏")

                            summary = cv_results.groupby("model")[["mape", "smape", "mase", "rmse"]].agg(
                                ["mean", "std"])

                            # Display metrics
                            for model in summary.index:
                                with st.expander(f"–ú–æ–¥–µ–ª—å: {model}"):
                                    col1, col2, col3, col4 = st.columns(4)

                                    with col1:
                                        mean_mape = summary.loc[model, ("mape", "mean")]
                                        std_mape = summary.loc[model, ("mape", "std")]
                                        st.metric(
                                            "MAPE",
                                            f"{mean_mape:.1f}%",
                                            f"¬±{std_mape:.1f}%"
                                        )

                                    with col2:
                                        mean_smape = summary.loc[model, ("smape", "mean")]
                                        std_smape = summary.loc[model, ("smape", "std")]
                                        st.metric(
                                            "sMAPE",
                                            f"{mean_smape:.1f}%",
                                            f"¬±{std_smape:.1f}%"
                                        )

                                    with col3:
                                        mean_mase = summary.loc[model, ("mase", "mean")]
                                        std_mase = summary.loc[model, ("mase", "std")]
                                        st.metric(
                                            "MASE",
                                            f"{mean_mase:.2f}",
                                            f"¬±{std_mase:.2f}"
                                        )

                                    with col4:
                                        mean_rmse = summary.loc[model, ("rmse", "mean")]
                                        st.metric(
                                            "RMSE",
                                            f"{mean_rmse:,.0f}"
                                        )

                            # Box plot of metrics
                            fig = go.Figure()

                            for model in cv_results["model"].unique():
                                model_data = cv_results[cv_results["model"] == model]
                                fig.add_trace(go.Box(
                                    y=model_data["mape"],
                                    name=model,
                                    boxmean=True
                                ))

                            fig.update_layout(
                                title="–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ MAPE –ø–æ —Ñ–æ–ª–¥–∞–º",
                                yaxis_title="MAPE (%)",
                                height=400
                            )

                            st.plotly_chart(fig, use_container_width=True)

                            # Download results
                            csv = cv_results.to_csv(index=False)
                            st.download_button(
                                "üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏",
                                data=csv,
                                file_name=f"cv_results_{metric_name}_{datetime.now():%Y%m%d}.csv",
                                mime="text/csv"
                            )

                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
        else:
            st.error("Enhanced Forecasting –º–æ–¥—É–ª—å –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

    else:  # –°—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        st.subheader("üéØ –°—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
        st.info("–ú–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑")

        # Scenario parameters
        col1, col2 = st.columns(2)
        with col1:
            scenario_type = st.selectbox(
                "–¢–∏–ø —Å—Ü–µ–Ω–∞—Ä–∏—è",
                ["–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞", "–°–µ–∑–æ–Ω–Ω—ã–π —à–æ–∫", "–†–∞–∑–æ–≤–æ–µ —Å–æ–±—ã—Ç–∏–µ"]
            )
        with col2:
            impact_percent = st.slider(
                "–í–µ–ª–∏—á–∏–Ω–∞ –≤–æ–∑–¥–µ–π—Å—Ç–≤–∏—è (%)",
                -50, 50, 0, step=5
            )

        if scenario_type == "–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞":
            st.markdown("""
            **–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞** - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ —É—Ä–æ–≤–Ω—è
            - –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = —Ä–æ—Å—Ç
            - –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ = —Å–ø–∞–¥
            """)
        elif scenario_type == "–°–µ–∑–æ–Ω–Ω—ã–π —à–æ–∫":
            st.markdown("""
            **–°–µ–∑–æ–Ω–Ω—ã–π —à–æ–∫** - –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Å–µ–∑–æ–Ω–Ω–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            - –í–ª–∏—è–µ—Ç –Ω–∞ –Ω–µ–¥–µ–ª—å–Ω—É—é –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å
            - –ú–æ–∂–µ—Ç –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∞–∑–¥–Ω–∏–∫–∏/–∞–∫—Ü–∏–∏
            """)
        else:
            event_date = st.date_input("–î–∞—Ç–∞ —Å–æ–±—ã—Ç–∏—è")
            event_duration = st.slider("–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (–¥–Ω–µ–π)", 1, 14, 3)

        if st.button("üìä –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å—Ü–µ–Ω–∞—Ä–∏–π"):
            st.info("–°—Ü–µ–Ω–∞—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏")
            # TODO: Implement scenario analysis

# ===================================
# TAB 8: Hierarchical Forecast
# ===================================
with tabHier:
    st.header("üèó Hierarchical Forecast (–∏–∑ —Ñ–∞–π–ª–æ–≤)")
    merch_file = Path(find_artifact("forecast_hier_merchant.csv"))
    mcc_file = Path(find_artifact("forecast_hier_mcc.csv"))
    total_file = Path(find_artifact("forecast_hier_total.csv"))
    if total_file.exists():
        df_total = pd.read_csv(total_file, parse_dates=["ds"])
        st.plotly_chart(px.line(df_total, x="ds", y="yhat", title="TOTAL (Bottom-Up)"), use_container_width=True)
    if mcc_file.exists():
        df_mcc = pd.read_csv(mcc_file, parse_dates=["ds"])
        mccs = sorted(df_mcc["mcc"].unique().tolist())
        sl = st.selectbox("MCC", mccs, index=0)
        st.plotly_chart(px.line(df_mcc[df_mcc["mcc"] == sl], x="ds", y="yhat", title=f"MCC {sl} (BU)"),
                        use_container_width=True)

# ===================================
# TAB 13: NL Assistant
# ===================================
with tab8:
    st.header("üòä NL-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç (Claude)");
    st.caption(f"–ò—Å—Ç–æ—á–Ω–∏–∫ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: {selected_table}")
    import json as _json

    CLAUDE_MODEL = os.getenv("CLAUDE_MODEL", "claude-3-5-sonnet-latest")
    ANTHROPIC_KEY = os.getenv("CLAUDE_API_KEY") or os.getenv("ANTHROPIC_API_KEY")


    def _safe_select(sql: str, limit: int = 200):
        s = sql.strip().lower()
        if not s.startswith("select") or any(x in s for x in
                                             (";", " insert ", " update ", " delete ", " drop ", " alter ", " rename ",
                                              " truncate ")):
            raise ValueError("–¢–æ–ª—å–∫–æ SELECT –±–µ–∑ ';'")
        if " limit " not in s: sql = sql.strip() + f" LIMIT {limit}"
        return ch_rows(sql)


    def _profile_cols(table: str, top_k: int = 5):
        cols = [c[0] for c in ch_rows(f"DESCRIBE {table}")]
        prof = {}
        for c in cols:
            try:
                total, nulls, uniqs = \
                ch_rows(f"SELECT count(), countIf({c} IS NULL OR toString({c})=''), uniq({c}) FROM {table}")[0]
                ex = ch_rows(f"SELECT {c} FROM {table} WHERE {c} IS NOT NULL AND toString({c})!='' LIMIT {top_k}")
                ch_type = [t[1] for t in ch_rows(f"DESCRIBE {table}") if t[0] == c][0]
                prof[c] = {"type": ch_type, "total": int(total), "nulls": int(nulls),
                           "null_rate": (nulls / total if total else 0), "uniques": int(uniqs),
                           "examples": [r[0] for r in ex]}
            except Exception as e:
                prof[c] = {"error": str(e)}
        return prof


    if not ANTHROPIC_KEY:
        st.warning("–ù–µ—Ç CLAUDE_API_KEY/ANTHROPIC_API_KEY –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏.")
    else:
        try:
            from anthropic import Anthropic

            anthropic_client = Anthropic(api_key=ANTHROPIC_KEY)
        except Exception as e:
            anthropic_client = None;
            st.error(f"Anthropic SDK error: {e}")

        if anthropic_client:
            if "nl_chat" not in st.session_state: st.session_state.nl_chat = []
            for role, text in st.session_state.nl_chat:
                with st.chat_message(role): st.markdown(text)

            SYSTEM = ("–¢—ã –ø–æ–º–æ–≥–∞–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å —Å ClickHouse. –û—Ç–≤–µ—á–∞–π –Ω–∞ —è–∑—ã–∫–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. "
                      "–ï—Å–ª–∏ –Ω—É–∂–µ–Ω —Ä–∞—Å—á—ë—Ç ‚Äî –≤–µ—Ä–Ω–∏ JSON –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π: "
                      '{"action":"sql","sql":"SELECT ..."} | {"action":"profile","table":"..."} | {"action":"echo","text":"..."} '
                      "–¢–æ–ª—å–∫–æ SELECT. –î–æ–±–∞–≤–ª—è–π LIMIT 200.")

            user_q = st.chat_input("–ù–∞–ø—Ä–∏–º–µ—Ä: ¬´–ü–æ–∫–∞–∂–∏ —Ç–æ–ø-10 MCC –ø–æ —Å—É–º–º–µ –∑–∞ –ø—Ä–æ—à–ª—ã–π –º–µ—Å—è—Ü¬ª")
            if user_q:
                st.session_state.nl_chat.append(("user", user_q))
                with st.chat_message("user"):
                    st.markdown(user_q)
                with st.chat_message("assistant"):
                    placeholder = st.empty()
                    try:
                        resp = anthropic_client.messages.create(model=CLAUDE_MODEL, max_tokens=800, temperature=0,
                                                                system=SYSTEM,
                                                                messages=[{"role": "user", "content": user_q}])
                        text = resp.content[0].text if resp and resp.content else ""
                    except Exception as e:
                        text = f'{{"action":"echo","text":"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ –º–æ–¥–µ–ª–∏: {e}"}}'
                    try:
                        block = _json.loads(text.strip())
                    except Exception:
                        placeholder.markdown(text)
                    else:
                        if block.get("action") == "sql":
                            sql = block.get("sql") or ""
                            try:
                                rows = _safe_select(sql)
                                df = pd.DataFrame(rows)
                                st.code(sql, language="sql");
                                st.dataframe(df, use_container_width=True);
                                placeholder.markdown("–ì–æ—Ç–æ–≤–æ ‚úÖ")
                            except Exception as e:
                                st.error(f"–û—à–∏–±–∫–∞ SELECT: {e}")
                        elif block.get("action") == "profile":
                            table = block.get("table") or selected_table
                            st.info(f"–ü—Ä–æ—Ñ–∏–ª—å: **{table}**");
                            st.json(_profile_cols(table));
                            placeholder.markdown("–ì–æ—Ç–æ–≤–æ ‚úÖ")
                        elif block.get("action") == "echo":
                            placeholder.markdown(block.get("text", ""))
                        else:
                            placeholder.markdown(text)