# scripts/analyze_data.py
"""
–ê–Ω–∞–ª–∏–∑ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
"""

import pandas as pd
import numpy as np
from pathlib import Path
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


def analyze_csv(file_path: str = 'data_100k.csv'):
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ CSV —Ñ–∞–π–ª–∞"""

    print("\n" + "=" * 70)
    print("üìä –ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê")
    print("=" * 70)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not Path(file_path).exists():
        print(f"‚ùå –§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("\n–ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –¥—Ä—É–≥–∏–µ —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏...")

        # –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
        possible_files = ['output.csv', 'data/data_100k.csv', 'data/output.csv']
        for alt_file in possible_files:
            if Path(alt_file).exists():
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª: {alt_file}")
                file_path = alt_file
                break
        else:
            print("‚ùå –§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return None

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print(f"\nüìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
    df = pd.read_csv(file_path, low_memory=False)

    file_size_mb = Path(file_path).stat().st_size / 1024 / 1024

    print(f"üìè –†–∞–∑–º–µ—Ä: {df.shape[0]:,} —Å—Ç—Ä–æ–∫ √ó {df.shape[1]} –∫–æ–ª–æ–Ω–æ–∫")
    print(f"üíæ –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size_mb:.2f} MB")
    print(f"üíæ –í –ø–∞–º—è—Ç–∏: {df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

    # –ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫
    print("\n" + "-" * 70)
    print("üìã –°–¢–†–£–ö–¢–£–†–ê –î–ê–ù–ù–´–•:")
    print("-" * 70)

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫–∏ –ø–æ —Ç–∏–ø–∞–º –¥–∞–Ω–Ω—ã—Ö
    dtypes_summary = df.dtypes.value_counts()
    print("\n–¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö:")
    for dtype, count in dtypes_summary.items():
        print(f"  ‚Ä¢ {dtype}: {count} –∫–æ–ª–æ–Ω–æ–∫")

    # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–ª–æ–Ω–æ–∫
    print(f"\n–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
    print("–ö–æ–ª–æ–Ω–∫–∏:", ", ".join(df.columns[:10]), "..." if len(df.columns) > 10 else "")

    # –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    print("\n" + "-" * 70)
    print("‚ùó –ü–†–û–ü–£–©–ï–ù–ù–´–ï –ó–ù–ê–ß–ï–ù–ò–Ø (—Ç–æ–ø-10):")
    print("-" * 70)

    null_counts = df.isnull().sum()
    null_percent = (null_counts / len(df)) * 100
    null_df = pd.DataFrame({
        '–ö–æ–ª–æ–Ω–∫–∞': null_counts.index,
        '–ü—Ä–æ–ø—É—â–µ–Ω–æ': null_counts.values,
        '–ü—Ä–æ—Ü–µ–Ω—Ç': null_percent.values
    })
    null_df = null_df[null_df['–ü—Ä–æ–ø—É—â–µ–Ω–æ'] > 0].sort_values('–ü—Ä–æ—Ü–µ–Ω—Ç', ascending=False).head(10)

    if not null_df.empty:
        for _, row in null_df.iterrows():
            print(f"  ‚Ä¢ {row['–ö–æ–ª–æ–Ω–∫–∞']}: {row['–ü—Ä–æ–ø—É—â–µ–Ω–æ']:,} ({row['–ü—Ä–æ—Ü–µ–Ω—Ç']:.1f}%)")
    else:
        print("  ‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –Ω–µ—Ç!")

    # –ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –ø–æ–ª–µ–π
    print("\n" + "-" * 70)
    print("üîë –ê–ù–ê–õ–ò–ó –ö–õ–Æ–ß–ï–í–´–• –ü–û–õ–ï–ô:")
    print("-" * 70)

    # –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏
    if 'transaction_code' in df.columns:
        print(f"\nüìù transaction_code:")
        print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {df['transaction_code'].nunique():,}")
        print(f"  ‚Ä¢ –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {df['transaction_code'].duplicated().sum():,}")
        if len(df) > 0:
            print(f"  ‚Ä¢ –ü—Ä–∏–º–µ—Ä: {df['transaction_code'].iloc[0]}")

    # –î–∞—Ç—ã
    if 'rday' in df.columns:
        print(f"\nüìÖ rday (timestamp):")
        rday_numeric = pd.to_numeric(df['rday'], errors='coerce')
        if not rday_numeric.isna().all():
            print(f"  ‚Ä¢ –ú–∏–Ω: {rday_numeric.min()}")
            print(f"  ‚Ä¢ –ú–∞–∫—Å: {rday_numeric.max()}")
            # –ü–æ–ø—Ä–æ–±—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –¥–∞—Ç—É
            try:
                min_date = pd.to_datetime(rday_numeric.min(), unit='s')
                max_date = pd.to_datetime(rday_numeric.max(), unit='s')
                days_range = (max_date - min_date).days
                print(f"  ‚Ä¢ –ü–µ—Ä–∏–æ–¥: {min_date.date()} - {max_date.date()} ({days_range} –¥–Ω–µ–π)")
            except:
                pass

    # –°—É–º–º—ã
    if 'amount_uzs' in df.columns:
        print(f"\nüí∞ amount_uzs:")
        amount_numeric = pd.to_numeric(df['amount_uzs'], errors='coerce')
        if not amount_numeric.isna().all():
            print(f"  ‚Ä¢ –ú–∏–Ω: {amount_numeric.min():,.0f} UZS")
            print(f"  ‚Ä¢ –ú–∞–∫—Å: {amount_numeric.max():,.0f} UZS")
            print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è: {amount_numeric.mean():,.0f} UZS")
            print(f"  ‚Ä¢ –ú–µ–¥–∏–∞–Ω–∞: {amount_numeric.median():,.0f} UZS")
            print(f"  ‚Ä¢ –°—É–º–º–∞: {amount_numeric.sum():,.0f} UZS")

    # MCC –∫–æ–¥—ã
    if 'mcc' in df.columns:
        print(f"\nüè™ MCC –∫–æ–¥—ã:")
        mcc_numeric = pd.to_numeric(df['mcc'], errors='coerce')
        if not mcc_numeric.isna().all():
            print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {mcc_numeric.nunique()}")
            print(f"  ‚Ä¢ –¢–æ–ø-5 –∫–∞—Ç–µ–≥–æ—Ä–∏–π:")
            top_mcc = df['mcc'].value_counts().head(5)
            for mcc, count in top_mcc.items():
                percent = count / len(df) * 100
                print(f"    - MCC {mcc}: {count:,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π ({percent:.1f}%)")

    # P2P
    if 'p2p_flag' in df.columns:
        print(f"\nüí∏ P2P –ø–µ—Ä–µ–≤–æ–¥—ã:")
        p2p_numeric = pd.to_numeric(df['p2p_flag'], errors='coerce')
        if not p2p_numeric.isna().all():
            p2p_count = p2p_numeric.sum()
            print(f"  ‚Ä¢ P2P —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {p2p_count:,.0f} ({p2p_count / len(df) * 100:.1f}%)")
            print(f"  ‚Ä¢ –û–±—ã—á–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(df) - p2p_count:,.0f} ({(len(df) - p2p_count) / len(df) * 100:.1f}%)")

    # –ë–∞–Ω–∫–∏
    if 'emitent_bank' in df.columns:
        print(f"\nüè¶ –ë–∞–Ω–∫–∏-—ç–º–∏—Ç–µ–Ω—Ç—ã (—Ç–æ–ø-5):")
        top_banks = df['emitent_bank'].value_counts().head(5)
        for bank, count in top_banks.items():
            percent = count / len(df) * 100
            print(f"  ‚Ä¢ {bank}: {count:,} –∫–∞—Ä—Ç ({percent:.1f}%)")

    # –†–µ–≥–∏–æ–Ω—ã
    if 'emitent_region' in df.columns:
        print(f"\nüìç –†–µ–≥–∏–æ–Ω—ã (—Ç–æ–ø-5):")
        top_regions = df['emitent_region'].value_counts().head(5)
        for region, count in top_regions.items():
            percent = count / len(df) * 100
            print(f"  ‚Ä¢ {region}: {count:,} —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π ({percent:.1f}%)")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
    print("\n" + "-" * 70)
    print("üîç –£–ù–ò–ö–ê–õ–¨–ù–û–°–¢–¨ –î–ê–ù–ù–´–•:")
    print("-" * 70)

    if 'hpan' in df.columns:
        unique_cards = df['hpan'].nunique()
        print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ä—Ç (hpan): {unique_cards:,}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–∞ –∫–∞—Ä—Ç—É: {len(df) / unique_cards:.1f}")

    if 'pinfl' in df.columns:
        unique_clients = df['pinfl'].nunique()
        print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ (pinfl): {unique_clients:,}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–∞ –∫–ª–∏–µ–Ω—Ç–∞: {len(df) / unique_clients:.1f}")

    if 'merchant_name' in df.columns:
        unique_merchants = df['merchant_name'].nunique()
        print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ä—á–∞–Ω—Ç–æ–≤: {unique_merchants:,}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–µ–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –Ω–∞ –º–µ—Ä—á–∞–Ω—Ç–∞: {len(df) / unique_merchants:.1f}")

    # –ü—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏
    print("\n" + "-" * 70)
    print("‚ö†Ô∏è –ü–û–¢–ï–ù–¶–ò–ê–õ–¨–ù–´–ï –ü–†–û–ë–õ–ï–ú–´:")
    print("-" * 70)

    issues = []

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–ª–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
    duplicates = df.duplicated().sum()
    if duplicates > 0:
        issues.append(f"–ù–∞–π–¥–µ–Ω–æ {duplicates:,} –ø–æ–ª–Ω—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å—Ç—Ä–æ–∫")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç
    date_columns = ['expire_date', 'issue_date']
    for date_col in date_columns:
        if date_col in df.columns:
            try:
                dates = pd.to_datetime(df[date_col], errors='coerce')
                invalid_dates = dates.isna().sum() - df[date_col].isna().sum()
                if invalid_dates > 0:
                    issues.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö {date_col}: {invalid_dates:,}")
            except:
                issues.append(f"–ü—Ä–æ–±–ª–µ–º—ã —Å —Ñ–æ—Ä–º–∞—Ç–æ–º {date_col}")

    if issues:
        for issue in issues:
            print(f"  ‚ö†Ô∏è {issue}")
    else:
        print("  ‚úÖ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print("\n" + "=" * 70)
    print("üìà –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print("=" * 70)
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π: {len(df):,}")
    if 'amount_uzs' in df.columns:
        total_amount = pd.to_numeric(df['amount_uzs'], errors='coerce').sum()
        print(f"  ‚Ä¢ –û–±—â–∏–π –æ–±—ä–µ–º: {total_amount:,.0f} UZS")
    if 'hpan' in df.columns:
        print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞—Ä—Ç: {df['hpan'].nunique():,}")
    if 'pinfl' in df.columns:
        print(f"  ‚Ä¢ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤: {df['pinfl'].nunique():,}")
    print("\n" + "=" * 70)

    return df


def quick_info(file_path: str = 'data_100k.csv'):
    """–ë—ã—Å—Ç—Ä–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–∞–π–ª–µ"""

    if not Path(file_path).exists():
        # –ò—â–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã
        for alt_file in ['output.csv', 'data/data_100k.csv', 'data/output.csv']:
            if Path(alt_file).exists():
                file_path = alt_file
                break
        else:
            print("‚ùå –§–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return

    file_size_mb = Path(file_path).stat().st_size / 1024 / 1024

    # –ü–æ–¥—Å—á–µ—Ç —Å—Ç—Ä–æ–∫ –±–µ–∑ –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
    with open(file_path, 'r', encoding='utf-8') as f:
        line_count = sum(1 for _ in f) - 1  # –ú–∏–Ω—É—Å –∑–∞–≥–æ–ª–æ–≤–æ–∫

    print(f"\nüìä –§–ê–ô–õ: {file_path}")
    print(f"   –†–∞–∑–º–µ—Ä: {file_size_mb:.2f} MB")
    print(f"   –°—Ç—Ä–æ–∫: {line_count:,}")
    print(f"   –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å—Ç—Ä–æ–∫–∏: {file_size_mb * 1024 / line_count:.0f} KB")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='–ê–Ω–∞–ª–∏–∑ CSV –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--file', type=str, default='data_100k.csv',
                        help='–ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É')
    parser.add_argument('--quick', action='store_true',
                        help='–ë—ã—Å—Ç—Ä–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏')

    args = parser.parse_args()

    if args.quick:
        quick_info(args.file)
    else:
        analyze_csv(args.file)